{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    #img = load_img(image_path, target_size=(224, 224))\n",
    "    #img = img_to_array(img)\n",
    "    #img = np.expand_dims(image_path, axis=0)\n",
    "    img = preprocess_input(image_path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "    euclidean_distance = source_representation - test_representation\n",
    "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "    euclidean_distance = np.sqrt(euclidean_distance)\n",
    "    return euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14475703239440918\n",
      "dataset\\new_face.2.jpg\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "from time import localtime, strftime\n",
    "import os\n",
    "import time\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('Cascades/haarcascade_frontalface_default.xml')\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "#video_capture = cv2.VideoCapture('rtsp://admin:Qq12345678@172.16.3.52:554/Streaming/Channels/101')\n",
    "#video_capture = cv2.VideoCapture('rtsp://admin:Qq12345678@172.16.3.52:554/Streaming/Channels/101')\n",
    "\n",
    "video_capture.set(3, 640) # set video width \n",
    "video_capture.set(4, 480) # set video height \n",
    "threshold=0.2\n",
    "(width, height) = (224, 224)\n",
    "idx=0\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', 800,600)\n",
    "\n",
    "\n",
    "a=[]\n",
    "b={}\n",
    "images=glob.glob('dataset/*.jpg')\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i])\n",
    "    face_resize = cv2.resize(image, (224, 224))\n",
    "    face_resize = face_resize.reshape(1,224,224,3)\n",
    "    img1_representation = vgg_face_descriptor.predict(preprocess_image(face_resize))[0,:]\n",
    "    b = {i:img1_representation}\n",
    "    a.append(b)\n",
    "    \n",
    "\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    processing_start_time = time.time()\n",
    "    time_counter = 0\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        frame,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        images=glob.glob('dataset/*.jpg')\n",
    "        rrec = cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        face = frame[y:y + h, x:x + w] \n",
    "        face_resize = cv2.resize(face, (width, height))\n",
    "        face_resize = face_resize.reshape(1,224,224,3)\n",
    "        img1_representation = vgg_face_descriptor.predict(preprocess_image(face_resize))[0,:]\n",
    "        \n",
    "        \n",
    "        cosines=[]\n",
    "        \n",
    "        for i in range(len(a)):\n",
    "            \n",
    "            cosine_similarity = findCosineSimilarity(img1_representation, a[i][i])\n",
    "            cosines.append(cosine_similarity)\n",
    "        \n",
    "        minimum = cosines.index(min(cosines))\n",
    "        #percent = (0.4-float(cosines[minimum]))*100/0.4\n",
    "        #print(str(percent)+'%')\n",
    "        print(cosines[minimum])\n",
    "        print(images[minimum])\n",
    "        print('-----------------------------')\n",
    "        \n",
    "        if float(cosines[minimum])<0.22:\n",
    "            text=str(images[minimum])\n",
    "            \n",
    "        if float(cosines[minimum])>0.25:\n",
    "            text='not found'\n",
    "            idx=len(a)\n",
    "            write_name = 'dataset/new_face.'+str(idx)+'.jpg'\n",
    "            cv2.imwrite(write_name, face)\n",
    "            \n",
    "            b={idx:img1_representation}\n",
    "            a.append(b)\n",
    "            print(len(images))\n",
    "            print(len(a))\n",
    "            print('Person added')\n",
    "            print('---------------------')\n",
    "            \n",
    "        \n",
    "        cv2.putText(rrec,text,(x,y), cv2.FONT_HERSHEY_SIMPLEX, 1,(167,34,56),1,cv2.LINE_AA)\n",
    "        \n",
    "      \n",
    "        time_counter += 1\n",
    "        if time.time()-start_time >= 60:\n",
    "            print(\"FPS: %.1f\" % (time_counter/(time.time() - start_time)))\n",
    "            time_counter = 0\n",
    "            frame_counter = 0\n",
    "            start_time = time.time()\n",
    "        \n",
    "        \n",
    "    cv2.imshow('image', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " enter user id end press ==> 2\n",
      "\n",
      " enter Directory name end press ==> 123\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) C:\\projects\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:350: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5cba6c5387f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.0) C:\\projects\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:350: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import os\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('Cascades/haarcascade_frontalface_default.xml')\n",
    "video_capture = cv2.VideoCapture('rtsp://admin:Qq12345678@172.16.3.52:554Streaming/Channels/101')\n",
    " \n",
    "face_id = input('\\n enter user id end press ==> ') \n",
    "dirname = input('\\n enter Directory name end press ==> ')\n",
    "os.mkdir(\"cam_data/\"+dirname)\n",
    "count = 0 \n",
    "\n",
    "while(True): \n",
    "    ret, frame = video_capture.read()\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        frame,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(224, 224)\n",
    "    )\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2) \n",
    "        count += 1 \n",
    "\n",
    "        if count<=20:\n",
    "            cv2.imwrite(\"cam_data/\"+dirname+\"/user.\"+str(count) + \".jpg\", frame[y:y+h,x:x+w])\n",
    "    \n",
    "\n",
    "        \n",
    "    cv2.imshow('image', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################             ПРобные внизу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import localtime, strftime\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "processing_start_time = time.time()\n",
    "time_counter = 0\n",
    "\n",
    "time_counter += 1\n",
    "\n",
    "if time.time()-start_time >= 60:\n",
    "    print(\"FPS: %.1f\" % (time_counter/(time.time() - start_time)))\n",
    "    time_counter = 0\n",
    "    frame_counter = 0\n",
    "    start_time = time.time()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548307874.1417284\n"
     ]
    }
   ],
   "source": [
    "from time import localtime, strftime\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0: array([ 2.7999353 ,  0.925722  ,  0.59417725, ...,  0.17142361,\n",
      "       -2.1760242 , -2.1836512 ], dtype=float32)}, {1: array([ 2.5935824,  3.3997478,  1.6893742, ..., -4.1313148,  2.7549067,\n",
      "        1.6185312], dtype=float32)}, {2: array([ 0.51078457, -2.1084054 ,  0.87694305, ..., -2.0840123 ,\n",
      "        1.6219534 ,  1.3938838 ], dtype=float32)}]\n",
      "[ 2.7999353   0.925722    0.59417725 ...  0.17142361 -2.1760242\n",
      " -2.1836512 ]\n",
      "[ 2.5935824  3.3997478  1.6893742 ... -4.1313148  2.7549067  1.6185312]\n",
      "[ 0.51078457 -2.1084054   0.87694305 ... -2.0840123   1.6219534\n",
      "  1.3938838 ]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "\n",
    "a=[]\n",
    "b={}\n",
    "c={}\n",
    "count=0\n",
    "images=glob.glob('dataset/*.jpg')\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i])\n",
    "    face_resize = cv2.resize(image, (224, 224))\n",
    "    face_resize = face_resize.reshape(1,224,224,3)\n",
    "    img1_representation = vgg_face_descriptor.predict(preprocess_image(face_resize))[0,:\n",
    "    b = {i:img1_representation}\n",
    "    a.append(b)\n",
    "print(a)\n",
    "for i in range(len(a)):\n",
    "    print(a[i][i])\n",
    "    \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {2: 5}}\n"
     ]
    }
   ],
   "source": [
    "new_dic={}\n",
    "\n",
    "new_dic.setdefault(1, {})[2] = 5\n",
    "print(new_dic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
